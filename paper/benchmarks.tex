\documentclass[journal]{vgtc}                % final (journal style)
%\documentclass[review,journal]{vgtc}         % review (journal style)
%\documentclass[widereview]{vgtc}             % wide-spaced review
%\documentclass[preprint,journal]{vgtc}       % preprint (journal style)
%\documentclass[electronic,journal]{vgtc}     % electronic version, journal

%% Uncomment one of the lines above depending on where your paper is
%% in the conference process. ``review'' and ``widereview'' are for review
%% submission, ``preprint'' is for pre-publication, and the final version
%% doesn't use a specific qualifier. Further, ``electronic'' includes
%% hyperreferences for more convenient online viewing.

%% Please use one of the ``review'' options in combination with the
%% assigned online id (see below) ONLY if your paper uses a double blind
%% review process. Some conferences, like IEEE Vis and InfoVis, have NOT
%% in the past.

%% Please note that the use of figures other than the optional teaser is not permitted on the first page
%% of the journal version.  Figures should begin on the second page and be
%% in CMYK or Grey scale format, otherwise, colour shifting may occur
%% during the printing process.  Papers submitted with figures other than the optional teaser on the
%% first page will be refused.

%% These three lines bring in essential packages: ``mathptmx'' for Type 1
%% typefaces, ``graphicx'' for inclusion of EPS figures. and ``times''
%% for proper handling of the times font family.

\usepackage{mathptmx}
\usepackage{graphicx}
\usepackage{times}

%% We encourage the use of mathptmx for consistent usage of times font
%% throughout the proceedings. However, if you encounter conflicts
%% with other math-related packages, you may want to disable it.

%% This turns references into clickable hyperlinks.
\usepackage[bookmarks,backref=true,linkcolor=black]{hyperref} %,colorlinks
\hypersetup{
  pdfauthor = {},
  pdftitle = {},
  pdfsubject = {},
  pdfkeywords = {},
  colorlinks=true,
  linkcolor= black,
  citecolor= black,
  pageanchor=true,
  urlcolor = black,
  plainpages = false,
  linktocpage
}

%% If you are submitting a paper to a conference for review with a double
%% blind reviewing process, please replace the value ``0'' below with your
%% OnlineID. Otherwise, you may safely leave it at ``0''.
\onlineid{0}

%% declare the category of your paper, only shown in review mode
\vgtccategory{Research}

%% allow for this line if you want the electronic option to work properly
\vgtcinsertpkg

%% In preprint mode you may define your own headline.
%\preprinttext{To appear in an IEEE VGTC sponsored conference.}

\include{defs}

%% Paper title.

\title{A Benchmark for Interactive Data Cubes}

%% This is how authors are specified in the journal style

%% indicate IEEE Member or Student Member in form indicated below
\author{Sean Stephens, Carlos Scheidegger}
\authorfooter{
%% insert punctuation at end of each item
\item
 Martha Stewart is with Martha Stewart Enterprises at Microsoft
 Research. E-mail: martha.stewart@marthastewart.com.
}

%other entries to be set up for journal
\shortauthortitle{Biv \MakeLowercase{\textit{et al.}}: Global Illumination for Fun and Profit}
%\shortauthortitle{Firstauthor \MakeLowercase{\textit{et al.}}: Paper Title}

\abstract{The data cube is a convenient abstraction for exploring
	multi-dimensional datasets. However, exploring large datasets as data cubes
	at interactive speeds requires specialized data structures and systems.
	Such systems exist, but there is no comprehensive comparison of these
	systems on realistic data. We present a benchmark that uses real-world and
	synthetic spatiotemporal data to explore the performance of these systems
	on realistic query sets.  We compare four existing systems using our
	implementation and demonstrate performance differences between them.
	Finally, we give a set of guidelines for choosing a system for
	applications.
}

%% Keywords that describe your work. Will show as 'Index Terms' in journal
%% please capitalize first letter and insert punctuation after last keyword
\keywords{Benchmark, Data Cube}

%% ACM Computing Classification System (CCS). 
%% See <http://www.acm.org/class/1998/> for details.
%% The ``\CCScat'' command takes four arguments.

\CCScatlist{ % not used in journal version
 \CCScat{K.6.1}{Management of Computing and Information Systems}%
{Project and People Management}{Life Cycle};
 \CCScat{K.7.m}{The Computing Profession}{Miscellaneous}{Ethics}
}

%% Uncomment below to include a teaser figure.
%%  \teaser{
%% \centering
%% \includegraphics[width=16cm]{CypressView}
%%  \caption{In the Clouds: Vancouver from Cypress Mountain.}
%%  }

%% Uncomment below to disable the manuscript note
%\renewcommand{\manuscriptnotetxt}{}

%% Copyright space is enabled by default as required by guidelines.
%% It is disabled by the 'review' option or via the following command:
% \nocopyrightspace

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% START OF THE PAPER %%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\large{

%% The ``\maketitle'' command must be the first command after the
%% ``\begin{document}'' command. It prepares and prints the title block.

%% the only exception to this rule is the \firstsection command
\firstsection{Introduction}

\maketitle

%% \section{Introduction} %for journal use above \firstsection{..} instead
Data cubes are a useful tool for exploring aggregates of high dimensional data
\cite{data_cubes}. However, executing queries on data cubes of large datasets
fast enough to support an interactive user interface is technically difficult
because current systems use excessive memory usage or demand a high degree of
parallelism \cite{nanocubes, parallel_paper}.

To address these problems, systems such as \textit{Nanocubes} and
\textit{Hashedcubes} allow fast queries in several dimensions by storing the
dataset in a server-side structure on dedicated hardware
\cite{nanocube}\cite{hashedcube}. This approach is much more complex and
resources intensive than simpler approaches such as linear scans on a client,
as in \textit{datavore} and \textit{crossfilter} \cite{datavore,crossfilter}.
On the other hand, it allows interactive exploration of data sets of tens of
millions of points. Alternatively, appropriate limits on the resolution or dimensionality of the dataset can reduce query latency to interactive rates, as is done in \textit{imMens} \cite{2013-immens}. 

Each of these systems were published with performance information exercising
the system on real-world test data. However, the published performance measures
are not, in general, comparable. Different datasets were used, and critical
parameters such as field resolution differ. As such, there is no complete
picture of data/schema configurations each of these systems is best suited for,
nor how each scales in different configurations.

This paper contributes a benchmark that allows direct comparisons of the query
performance of these systems on realistic data. Additionally, we describe an
implementation for nanocubes and hashedcubes. Finally, we
give guidance for choosing between and configuring these systems based on
dataset and application.


\section{Related work}

Large data visualization frequently requires computing aggregations over the
entirety of a dataset to produce counts, histograms, and density plots
\cite{?}. For an interactive visualization, supporting arbitrary aggregations
smoothly on large datasets presents a problem due to performance. To maintain
an interactive user experience, a plot of aggregates should refresh with low
latency (This is not merely an aesthetic concern; high latency induces large
changes in a user's exploration to the detriment of analysis, as explored in
\cite{2014-latency} \FIXME{Inline citation here?}). However, naive techniques
for computing aggregations, namely linear scans over the dataset, do not scale
to datasets with tens of millions of entries.

In this paper we are specifically interested in systems that allow fast queries on large spatiotemporal datasets. Specifically, we mean systems that efficiently support data with the following attributes:

\begin{itemize}
	\item $1$ or more \textit{spatial} attributes, defined as a pair of related coordinates from an ordered domain, often latitude and longitude.
	\item $0$ or more \textit{categorical} attributes, defined as a value from a discrete domain.
	\item $1$ \textit{time} attribute, defined as an attribute over an ordered domain.
\end{itemize}

\subsection{Existing Systems}

Several solutions exist for this problem. Nanocubes builds a
hierarchical tree of agregations that fits in main memory, in contrast to
traditional relational database data cube aggregations which must be stored on
disk \cite{nanocubes}. This system provides query performance that is fast
enough for interactive applications and suports queries at different
resolutions (up to the limits of the underlying data), but is memory intensive.

A new alternative to nanocubes is hashedcubes. This system
achieves similar performance for many common queries but consumes less memory
by using a single sorted array, at the cost of poor performance in some cases.
Additionally, it does not allow fine queries in sparsely populated areas, as a
tradeoff to prevent poor performance in other areas.

\textit{ImMens} pre-computes and compactly stores aggregates as so-called
``data-tiles'' \cite{2013-immens}. These tiles can be quickly queried using the
GPU on the client.  ImMens achieves very fast response time (limited by the GPU
refresh rate) and does not require a dedicated server, but requires
pre-computing data tiles and limits on the resolution and dimensionality of the
underlying data.

An alternate solution to this performance challenge is sampling.
\textit{BlinkDB} uses parallelism and intelligent sampling strategies to
achieve approximate query results with $2-10\%$ error and response times on the
order of $2$ seconds \cite{blinkdb}. This system is designed for datasets on
the order of terabytes in size, but does not provide response times fast enough
for an interactive application \FIXME{In the sense we are describing -- should
specify this more carefully}. For datasets with tens to hundreds of millions of
points, the previously described systems can produce much more accurate results
using less time and resources. For this reason, we will not benchmark sampling
systems here. \FIXME{This hardly seems like a comprehensive treatment of
sampling systems -- need to look at more references}

Finally, for small datasets with $1-5$ million elements, it is possible to do
queries at near interactive latencies in a web browser. Systems such as
\textit{datavore} and \textit{crossfilter} take this approach
\cite{crossfilter,datavore}. While this approach does not scale to tens and
hundreds of millions of data points due to latency and bandwidth consumption,
it is a simple solution for small datasets. 

In this paper we will describe a benchmark aimed at nanocubes, hashedcubes,
imMens, and crossfilter/datavore. Despite the performance measurements reported
in publications for these systems, it is not possible to definitively state how
each of these systems perform relative to each other. It is similarly not
well-understood how each of these systems scale with dataset size,
dimensionality, and query distribution. Our contribution is to rectify this
situation and provide guidance for choosing between these systems for
applications.

\TODO{Why are we not covering streaming}

\TODO{Why is TPC not applicable? On-disk, not specifically spatiotemporal}

\TODO{"Implementing Data Cubes Efficiently" should be cited}

\section{Benchmark}

\FIXME{ How precise should thie specification be? }

We have the following goals for a benchmark:

\begin{itemize}
	\item \textbf{Use realistic data and queries.} The systems under test
		should operate on of datasets representative of real-world data. This
		means datasets of large scale and with varied schema that show up in
		real-world application. Specifically, the benchmark must test datasets
		that range from $1-100$ million data points, with $3$ or more dimensions
		\FIXME{Why is this the right range? What evidence do we have for
		this?}\cite{...}.  Additionally, the queries run against the systems
		under test should be realistic.  They should reflect queries that
		result from supporting actual user behavior.

	\item \textbf{Exercise entire data-query space.} The set of configurations
		and query sets used by the benchmark should span the full range of data
		sets for which these systems may be reasonably applied. 
		
	\item \textbf{Efficiently cover data-query space.} The set of possible
		systems, configurations, datasets, and queries is very large.
		Pragmatically, it is important to choose tests that complete our goals
		without requiring excessive time or resources to complete.

\end{itemize}

\subsection{Realistic data and queries}

In the interest of supporting further research and consistent performance measurements across systems, part of the benchmark will be based on publicly-available data sets. However, we will supplement this with synthetic data when there is no suitable public dataset for testing a particular aspect of performance.

We identify the following categories of datasets as distinct categories for which we expect significant deviation in performance between the systems under test. \FIXME{Why?}

\begin{itemize}

	\item ~$1$ Million data points, $3-32$ dimensions. Examples: Splom, Anything

	\item $5-10$ Million data points, $3-10$ dimensions. Examples: Brightkite,
		Gowalla, Splom

	\item $100+$ Million data points, $3-5$ dimensions. Examples: Airline,
		Splom

	\item A dataset with more than one spatial attribute \FIXME{Taxicab?}.

	\FIXME{Is a spatial attribute 1 or 2 dimensions}
\end{itemize}

The first three classes of dataset consist of one spatial attribute, 1 temporal
attribute, and $0-29$ categorical attributes. Conservatively, supposing that
categorical dimensions have small domains of size $k$, it is clear that it is
unreasonable to exhaustively search up to $k^{30}$ combinations of categorical
variables; the problem is exacerbated when we consider that we would ideally
test each of those combinations against many different spatial and time ranges.
In these cases, we will show that a regular but sparse sampling of the
categorical variable combinations will yield sufficient information about the
performance characteristics of the systems under test. \FIXME{Should consider trying to apply low-discrepancy sequences here}

\TODO{Explain synthetic query sequences (fat, thin, categorical)}

For smaller numbers of dimensions, it will be possible to exhaustively check all combinations of categorical variables \FIXME{Why would we not sample anyway to make it faster?}.


\TODO{Explain why user traces are representative of query patterns}

\TODO{Describe what we want to measure; memory, query time, build time}

\section{Experiments}

\TODO{Plots, details of experiments (compiling, machine, how many times, more detail)}

\TODO{Interpretation of results}

\section{Discussion}

\TODO{How to improve the benchmark itself}

\TODO{Different interface/system induces different user behavior (cite Jeff Heer, The effects of interactive latency on explorative visual analysis)}

\TODO{Can be extended to new data, hopefully new queries}

\section{Conclusion and Future Work}

\TODO{What this means for making new systems (easier, negative space)}

\TODO{What next (making things parameterizable, what is the next research question...)}

% \begin{table}
% %% Table captions on top in journal version
%  \caption{SciVis Paper Acceptance Rate: 1994-2006}
%  \label{vis_accept}
%  \scriptsize
%  \begin{center}
%    \begin{tabular}{cccc}
%      Year & Submitted & Accepted & Accepted (\%)\\
%    \hline
%      1994 &  91 & 41 & 45.1\\
%      1995 & 102 & 41 & 40.2\\
%      1996 & 101 & 43 & 42.6\\
%      1997 & 117 & 44 & 37.6\\
%      1998 & 118 & 50 & 42.4\\
%      1999 & 129 & 47 & 36.4\\
%      2000 & 151 & 52 & 34.4\\
%      2001 & 152 & 51 & 33.6\\
%      2002 & 172 & 58 & 33.7\\
%      2003 & 192 & 63 & 32.8\\
%      2004 & 167 & 46 & 27.6\\
%      2005 & 268 & 88 & 32.8\\
%      2006 & 228 & 63 & 27.6
%    \end{tabular}
%  \end{center}
% \end{table}

% \begin{figure}[htb]
%  \centering
%  \includegraphics[width=1.5in]{sample}
%  \caption{Sample illustration.}
% \end{figure}


%% if specified like this the section will be committed in review mode
\acknowledgments{
The authors wish to thank A, B, C. This work was supported in part by
a grant from XYZ.}

\bibliographystyle{abbrv}
%%use following if all content of bibtex file should be shown
%\nocite{*}
\bibliography{benchmarks}
} %large
\end{document}
